# -*- coding: utf-8 -*-
"""youtube-comments-spam-classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CZS0Vad6y6kUOt811I3hVW8cDZspvKgQ

# YouTube Comments Spam Classifier

### Import modules
"""

import pandas as pd
import zipfile
import pickle

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer

from sklearn.naive_bayes import MultinomialNB

from sklearn.metrics import confusion_matrix, classification_report



"""### Import dataset files from Google Drive"""

Psy = pd.read_csv("/content/Youtube01-Psy.csv")
Katy = pd.read_csv("/content/Youtube02-KatyPerry.csv")
LMFAO = pd.read_csv("/content/Youtube03-LMFAO.csv")
Eminem = pd.read_csv("/content/Youtube04-Eminem.csv")
Shakira = pd.read_csv("/content/Youtube05-Shakira.csv")

data = pd.concat([Psy, Katy, LMFAO, Eminem, Shakira])
data.drop(["COMMENT_ID", "DATE", "AUTHOR"], axis=1, inplace=True)
data.info()

"""### Splitting dataset into train/test sets"""

X_train, X_test, y_train, y_test = train_test_split(data["CONTENT"], data["CLASS"])

"""### Tokenizing comments in training set and applying TF-IDF vectorizer on training set"""

tfidf_vect = TfidfVectorizer(use_idf=True, lowercase=True)
X_train_tfidf = tfidf_vect.fit_transform(X_train)
X_train_tfidf.shape

"""### Training the multinomial Naive Bayes model"""

model = MultinomialNB()
model.fit(X_train_tfidf, y_train)

"""### Generate predictions on test set"""

X_test_tfidf = tfidf_vect.transform(X_test)
predictions = model.predict(X_test_tfidf)

"""### Generate model performance metrics"""

confusion_matrix(y_test, predictions)

print(classification_report(y_test, predictions))

model.score(X_test_tfidf, y_test)

"""### Exporting the model and TF-IDF vectorizer"""

with open("model.pkl", "wb") as model_file:
  pickle.dump(model, model_file)

with open("tfidf-vect.pkl", "wb") as tfidf_vect_file:
  pickle.dump(tfidf_vect, tfidf_vect_file)

